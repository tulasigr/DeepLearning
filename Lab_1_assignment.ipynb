{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b4dac59-818c-4516-b394-12192449650c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: images - Shape: (2626, 128, 128, 3) - Data type: uint8\n",
      "Dataset: labels - Shape: (2626,) - Data type: int32\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Open the HDF5 file\n",
    "train_path = r'C:\\Users\\tulas\\OneDrive\\Desktop\\RVU\\Sem5\\DL\\Lab1\\Train.h5'  # Replace with your file path\n",
    "with h5py.File(train_path, 'r') as file:\n",
    "    # Recursively print the structure of the file\n",
    "    def print_structure(name, obj):\n",
    "        if isinstance(obj, h5py.Group):\n",
    "            print(f\"Group: {name}\")\n",
    "        elif isinstance(obj, h5py.Dataset):\n",
    "            print(f\"Dataset: {name} - Shape: {obj.shape} - Data type: {obj.dtype}\")\n",
    "\n",
    "    file.visititems(print_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40504d6a-fdc5-4053-a555-67bb09d00f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: images - Shape: (120, 128, 128, 3) - Data type: uint8\n",
      "Dataset: labels - Shape: (120,) - Data type: int32\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Open the HDF5 file\n",
    "test_path = r'C:\\Users\\tulas\\OneDrive\\Desktop\\RVU\\Sem5\\DL\\Lab1\\Test.h5'  # Replace with your file path\n",
    "with h5py.File(test_path, 'r') as file:\n",
    "    # Recursively print the structure of the file\n",
    "    def print_structure(name, obj):\n",
    "        if isinstance(obj, h5py.Group):\n",
    "            print(f\"Group: {name}\")\n",
    "        elif isinstance(obj, h5py.Dataset):\n",
    "            print(f\"Dataset: {name} - Shape: {obj.shape} - Data type: {obj.dtype}\")\n",
    "\n",
    "    file.visititems(print_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdb578ec-81dc-466d-a053-043de2fcb625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the file: ['images', 'labels']\n",
      "Keys in the file: ['images', 'labels']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "def inspect_h5_file(file_path):\n",
    "    with h5py.File(file_path, \"r\") as file:\n",
    "        print(\"Keys in the file:\", list(file.keys()))\n",
    "\n",
    "# Inspect the training file\n",
    "inspect_h5_file(\"Train.h5\")\n",
    "\n",
    "# Inspect the test file\n",
    "inspect_h5_file(\"Test.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30e2f891-3317-4a54-b325-98f16232145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "def load_data(train_path, test_path):\n",
    "    train_dataset = h5py.File(train_path, \"r\")\n",
    "    test_dataset = h5py.File(test_path, \"r\")\n",
    "    \n",
    "    train_x_orig = np.array(train_dataset[\"images\"][:])  # Replace with the correct key\n",
    "    train_y_orig = np.array(train_dataset[\"labels\"][:])  # Replace with the correct key\n",
    "    \n",
    "    test_x_orig = np.array(test_dataset[\"images\"][:])  # Replace with the correct key\n",
    "    test_y_orig = np.array(test_dataset[\"labels\"][:])  # Replace with the correct key\n",
    "    \n",
    "    return train_x_orig, train_y_orig, test_x_orig, test_y_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e25dc9-5c08-4a73-9239-6c6e7e90df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the dataset\n",
    "def preprocess_data(train_x_orig, test_x_orig):\n",
    "    train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T\n",
    "    test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
    "    \n",
    "    train_x = train_x_flatten / 255.\n",
    "    test_x = test_x_flatten / 255.\n",
    "    \n",
    "    return train_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69a64f03-c0d4-4a14-ba78-43300ca94a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax function\n",
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z, axis=0, keepdims=True))\n",
    "    return exp_z / np.sum(exp_z, axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a55e896-524e-4f73-b3d8-51781de6a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function for multi-class classification\n",
    "def compute_cost(A, Y):\n",
    "    m = Y.shape[1]\n",
    "    cost = -np.sum(Y * np.log(A)) / m\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fddc3af2-aaed-4509-b848-b664f8bfec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent\n",
    "def gradient_descent(X, Y, learning_rate, num_iterations):\n",
    "    n_x, m = X.shape\n",
    "    n_y = Y.shape[0]\n",
    "    \n",
    "    W = np.random.randn(n_y, n_x) * 0.01\n",
    "    b = np.zeros((n_y, 1))\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        Z = np.dot(W, X) + b\n",
    "        A = softmax(Z)\n",
    "        \n",
    "        cost = compute_cost(A, Y)\n",
    "        \n",
    "        dZ = A - Y\n",
    "        dW = np.dot(dZ, X.T) / m\n",
    "        db = np.sum(dZ, axis=1, keepdims=True) / m\n",
    "        \n",
    "        W -= learning_rate * dW\n",
    "        b -= learning_rate * db\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"Cost after iteration {i}: {cost}\")\n",
    "    \n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f1fe797-b58e-484f-8727-a946e61322ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict function\n",
    "def predict(W, b, X):\n",
    "    Z = np.dot(W, X) + b\n",
    "    A = softmax(Z)\n",
    "    predictions = np.argmax(A, axis=0)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d1ebc43-8658-4c91-8c8f-d6750639fc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoding\n",
    "def convert_to_one_hot(Y, num_classes):\n",
    "    Y_one_hot = np.eye(num_classes)[Y.reshape(-1)].T\n",
    "    return Y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfa6c7e8-bb8d-4833-9cbc-bcc06c196f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "train_x_orig, train_y_orig, test_x_orig, test_y_orig = load_data(\"Train.h5\", \"Test.h5\")\n",
    "train_x, test_x = preprocess_data(train_x_orig, test_x_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c744e14-6d7f-4e75-915a-26e93db9d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(np.unique(train_y_orig))\n",
    "train_y = convert_to_one_hot(train_y_orig, num_classes)\n",
    "test_y = convert_to_one_hot(test_y_orig, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b270c8ef-7cf4-4239-80b7-f5aeadd4d4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 2.083464296177889\n",
      "Cost after iteration 100: 1.28923885425293\n",
      "Cost after iteration 200: 1.2108923580991668\n",
      "Cost after iteration 300: 1.1637875065670558\n",
      "Cost after iteration 400: 1.1280831256858779\n",
      "Cost after iteration 500: 1.098361420690051\n",
      "Cost after iteration 600: 1.0724300417335393\n",
      "Cost after iteration 700: 1.0491795217274689\n",
      "Cost after iteration 800: 1.0279603837157922\n",
      "Cost after iteration 900: 1.0083528965516984\n",
      "Cost after iteration 1000: 0.99006650082975\n",
      "Cost after iteration 1100: 0.9728899339039836\n",
      "Cost after iteration 1200: 0.9566638961620838\n",
      "Cost after iteration 1300: 0.941264840025503\n",
      "Cost after iteration 1400: 0.9265947439975201\n",
      "Cost after iteration 1500: 0.9125743465664475\n",
      "Cost after iteration 1600: 0.8991385001383407\n",
      "Cost after iteration 1700: 0.8862328858638808\n",
      "Cost after iteration 1800: 0.873811634885109\n",
      "Cost after iteration 1900: 0.8618355713588642\n",
      "Cost after iteration 2000: 0.8502708923591535\n",
      "Cost after iteration 2100: 0.8390881609624137\n",
      "Cost after iteration 2200: 0.8282615277454974\n",
      "Cost after iteration 2300: 0.8177681214206138\n",
      "Cost after iteration 2400: 0.8075875664358937\n",
      "Cost after iteration 2500: 0.7977015970791106\n",
      "Cost after iteration 2600: 0.7880937457767402\n",
      "Cost after iteration 2700: 0.7787490890464478\n",
      "Cost after iteration 2800: 0.7696540386938159\n",
      "Cost after iteration 2900: 0.7607961688433121\n",
      "Cost after iteration 3000: 0.7521640715954181\n",
      "Cost after iteration 3100: 0.7437472357359146\n",
      "Cost after iteration 3200: 0.735535944148487\n",
      "Cost after iteration 3300: 0.7275211865092583\n",
      "Cost after iteration 3400: 0.7196945845503462\n",
      "Cost after iteration 3500: 0.7120483277255096\n",
      "Cost after iteration 3600: 0.7045751175350919\n",
      "Cost after iteration 3700: 0.6972681190995615\n",
      "Cost after iteration 3800: 0.6901209188328639\n",
      "Cost after iteration 3900: 0.6831274872747991\n",
      "Cost after iteration 4000: 0.6762821463078822\n",
      "Cost after iteration 4100: 0.6695795401178557\n",
      "Cost after iteration 4200: 0.6630146093651107\n",
      "Cost after iteration 4300: 0.6565825681222102\n",
      "Cost after iteration 4400: 0.6502788832044845\n",
      "Cost after iteration 4500: 0.6440992555796353\n",
      "Cost after iteration 4600: 0.6380396035908612\n",
      "Cost after iteration 4700: 0.6320960477682059\n",
      "Cost after iteration 4800: 0.6262648970362451\n",
      "Cost after iteration 4900: 0.620542636154064\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "learning_rate = 0.001\n",
    "num_iterations = 5000\n",
    "W, b = gradient_descent(train_x, train_y, learning_rate, num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "482d0a2a-527f-450e-a758-e77893eaa3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "train_predictions = predict(W, b, train_x)\n",
    "test_predictions = predict(W, b, test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccc68523-abfc-412f-ac56-8a8e48462286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 84.35%\n",
      "Test accuracy: 43.33%\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "train_accuracy = np.mean(train_predictions == np.argmax(train_y, axis=0)) * 100\n",
    "test_accuracy = np.mean(test_predictions == np.argmax(test_y, axis=0)) * 100\n",
    "\n",
    "print(f\"Train accuracy: {train_accuracy:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cd56b2-44b0-4055-866f-678ebf720ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
